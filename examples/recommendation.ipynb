{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9011848a-5aca-451b-9303-113f363b8c92",
   "metadata": {},
   "source": [
    "# Recommendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04d2f22-ebff-4990-bd80-c2766b7da53b",
   "metadata": {},
   "source": [
    "Two approaches to build a recommendation system with some common processes are :\n",
    "1. Classfication Algorithms\n",
    "2. Clustering Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829270e4-267c-44f4-9fca-67c0a1e4f961",
   "metadata": {},
   "source": [
    "![](../images/DataMiningProject.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f642c61a-2f40-44b5-922d-382c6058d7c3",
   "metadata": {},
   "source": [
    "## Using Clustering algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf8239aa-af6a-4b93-8ed6-21f446eb4877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended items:\n",
      "   Color      Category       Size       Type  Cluster\n",
      "1   blue  architecture     medium   portrait        0\n",
      "0  green        nature  thumbnail  landscape        0\n",
      "2   blue        people     medium  landscape        0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = [\n",
    "    [\"green\", \"nature\", \"thumbnail\", \"landscape\"],\n",
    "    [\"blue\", \"architecture\", \"medium\", \"portrait\"],\n",
    "    [\"blue\", \"people\", \"medium\", \"landscape\"],\n",
    "    [\"yellow\", \"nature\", \"medium\", \"portrait\"],\n",
    "    [\"green\", \"nature\", \"thumbnail\", \"landscape\"],\n",
    "    [\"blue\", \"people\", \"medium\", \"landscape\"],\n",
    "    [\"blue\", \"nature\", \"thumbnail\", \"portrait\"],\n",
    "    [\"yellow\", \"architecture\", \"thumbnail\", \"landscape\"],\n",
    "    [\"blue\", \"people\", \"medium\", \"portrait\"],\n",
    "    [\"yellow\", \"nature\", \"medium\", \"landscape\"],\n",
    "    [\"yellow\", \"people\", \"thumbnail\", \"portrait\"],\n",
    "    [\"blue\", \"people\", \"medium\", \"landscape\"],\n",
    "    [\"red\", \"architecture\", \"thumbnail\", \"landscape\"],\n",
    "]\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = [LabelEncoder() for _ in range(len(data[0]))]\n",
    "encoded_data = []\n",
    "for i, column in enumerate(zip(*data)):\n",
    "    encoded_data.append(label_encoders[i].fit_transform(column))\n",
    "\n",
    "X = list(zip(*encoded_data))  # Features\n",
    "\n",
    "# Clustering\n",
    "k = 2  # Number of clusters\n",
    "kmeans = KMeans(n_clusters=k, n_init=10)\n",
    "kmeans.fit(X)\n",
    "clusters = kmeans.labels_\n",
    "\n",
    "# Add cluster labels to the original data\n",
    "data_with_clusters = pd.DataFrame(data, columns=[\"Color\", \"Category\", \"Size\", \"Type\"])\n",
    "data_with_clusters[\"Cluster\"] = clusters\n",
    "\n",
    "# Recommendation function\n",
    "def recommend_items(cluster, data_with_clusters):\n",
    "    items_in_cluster = data_with_clusters[data_with_clusters[\"Cluster\"] == cluster]\n",
    "    recommended_items = items_in_cluster.sample(n=3)  # Sample 3 items from the cluster\n",
    "    return recommended_items\n",
    "\n",
    "# Example usage\n",
    "user_interaction = [\"green\", \"nature\", \"thumbnail\", \"landscape\"]  # Assuming user interacted with this item\n",
    "encoded_interaction = [label_encoders[i].transform([val])[0] for i, val in enumerate(user_interaction)]\n",
    "cluster = kmeans.predict([encoded_interaction])[0]\n",
    "recommendations = recommend_items(cluster, data_with_clusters)\n",
    "print(\"Recommended items:\")\n",
    "print(recommendations)\n",
    "\n",
    "reco_list = recommendations.values.tolist()\n",
    "reco_list = [sublist[:-1] for sublist in reco_list]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03db3717-92dc-48c0-818d-a088d0e42078",
   "metadata": {},
   "source": [
    "## Using classification algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c55702d2-b1e1-4443-b5b1-d4a1075c31be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6666666666666666\n",
      "[['blue', 'nature', 'thumbnail', 'portrait'], ['green', 'nature', 'thumbnail', 'landscape'], ['blue', 'people', 'medium', 'landscape']]\n",
      "Prediction for the sample item: Favorite\n",
      "Prediction for the sample item: Favorite\n",
      "Prediction for the sample item: Favorite\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Sample data\n",
    "data = [\n",
    "    [\"green\", \"nature\", \"thumbnail\", \"landscape\"],\n",
    "    [\"blue\", \"architecture\", \"medium\", \"portrait\"],\n",
    "    [\"blue\", \"people\", \"medium\", \"landscape\"],\n",
    "    [\"yellow\", \"nature\", \"medium\", \"portrait\"],\n",
    "    [\"green\", \"nature\", \"thumbnail\", \"landscape\"],\n",
    "    [\"blue\", \"people\", \"medium\", \"landscape\"],\n",
    "    [\"blue\", \"nature\", \"thumbnail\", \"portrait\"],\n",
    "    [\"yellow\", \"architecture\", \"thumbnail\", \"landscape\"],\n",
    "    [\"blue\", \"people\", \"medium\", \"portrait\"],\n",
    "    [\"yellow\", \"nature\", \"medium\", \"landscape\"],\n",
    "    [\"yellow\", \"people\", \"thumbnail\", \"portrait\"],\n",
    "    [\"blue\", \"people\", \"medium\", \"landscape\"],\n",
    "    [\"red\", \"architecture\", \"thumbnail\", \"landscape\"],\n",
    "]\n",
    "result = [\n",
    "    \"Favorite\",\n",
    "    \"NotFavorite\",\n",
    "    \"Favorite\",\n",
    "    \"Favorite\",\n",
    "    \"Favorite\",\n",
    "    \"Favorite\",\n",
    "    \"Favorite\",\n",
    "    \"NotFavorite\",\n",
    "    \"NotFavorite\",\n",
    "    \"Favorite\",\n",
    "    \"Favorite\",\n",
    "    \"NotFavorite\",\n",
    "    \"NotFavorite\",\n",
    "]\n",
    "\n",
    "# Encode categorical features and labels\n",
    "label_encoders = [LabelEncoder() for _ in range(len(data[0]))]\n",
    "encoded_data = []\n",
    "for i, column in enumerate(zip(*data)):\n",
    "    encoded_data.append(label_encoders[i].fit_transform(column))\n",
    "\n",
    "X = list(zip(*encoded_data))  # Features\n",
    "y = result  # Labels\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the logistic regression classifier\n",
    "classifier = svm.SVC()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Sample prediction\n",
    "print(reco_list)\n",
    "for prediction in reco_list:\n",
    "    encoded_item = [label_encoders[i].transform([val])[0] for i, val in enumerate(prediction)]\n",
    "    prediction = classifier.predict([encoded_item])[0]\n",
    "    print(f\"Prediction for the sample item: {prediction}\")\n",
    "    \n",
    "# sample_item = [\"green\", \"nature\", \"thumbnail\", \"landscape\"]  # Sample item attributes\n",
    "# encoded_item = [label_encoders[i].transform([val])[0] for i, val in enumerate(sample_item)]\n",
    "# prediction = classifier.predict([encoded_item])[0]\n",
    "# print(f\"Prediction for the sample item: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391880e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pynput==1.7.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea9e25d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key.right pressed\n",
      "Right arrow key pressed\n",
      "Key.left pressed\n",
      "Left arrow key pressed\n",
      "Key.esc pressed\n",
      "Escape key pressed, ending program\n"
     ]
    }
   ],
   "source": [
    "from pynput import keyboard\n",
    "\n",
    "def on_press(key):\n",
    "    print('{0} pressed'.format(\n",
    "        key))\n",
    "    try:\n",
    "        if key == keyboard.Key.esc:\n",
    "            print('Escape key pressed, ending program')\n",
    "            return False  # Stop listener\n",
    "        elif key == keyboard.Key.left:\n",
    "            print('Left arrow key pressed')\n",
    "        elif key == keyboard.Key.right:\n",
    "            print('Right arrow key pressed')\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "with keyboard.Listener(on_press=on_press) as listener:\n",
    "    listener.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f6a19598",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fallcon/.local/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=['green' 'red' 'blue'].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 45\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m properties \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# Encode color and tags subarrays using OneHotEncoder\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     onehot_encoder \u001b[38;5;241m=\u001b[39m OneHotEncoder(sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 45\u001b[0m     color_data \u001b[38;5;241m=\u001b[39m \u001b[43monehot_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproperties\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     category_data \u001b[38;5;241m=\u001b[39m onehot_encoder\u001b[38;5;241m.\u001b[39mfit_transform(properties[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# Encode size and orientation feature using LabelEncoder\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 157\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    160\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    162\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    163\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:916\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    915\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 916\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:985\u001b[0m, in \u001b[0;36mOneHotEncoder.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    975\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    976\u001b[0m         (\n\u001b[1;32m    977\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`sparse` was renamed to `sparse_output` in version 1.2 and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    981\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    982\u001b[0m     )\n\u001b[1;32m    983\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparse_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparse\n\u001b[0;32m--> 985\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhandle_unknown\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_unknown\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_drop_idx()\n\u001b[1;32m    991\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_features_outs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_n_features_outs()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:78\u001b[0m, in \u001b[0;36m_BaseEncoder._fit\u001b[0;34m(self, X, handle_unknown, force_all_finite, return_counts, return_and_ignore_missing_for_infrequent)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_feature_names(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 78\u001b[0m X_list, n_samples, n_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_X\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m n_features\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategories \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:44\u001b[0m, in \u001b[0;36m_BaseEncoder._check_X\u001b[0;34m(self, X, force_all_finite)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03mPerform custom check_array:\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m- convert list of strings to object dtype\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m# if not a dataframe, do normal check_array validation\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m     X_temp \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(X_temp\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mstr_):\n\u001b[1;32m     46\u001b[0m         X \u001b[38;5;241m=\u001b[39m check_array(X, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mobject\u001b[39m, force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:938\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    936\u001b[0m     \u001b[38;5;66;03m# If input is 1D raise error\u001b[39;00m\n\u001b[1;32m    937\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 938\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    939\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    940\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    941\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    942\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    943\u001b[0m         )\n\u001b[1;32m    945\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    946\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    947\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    949\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=['green' 'red' 'blue'].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "data = [\n",
    "    [[\"green\", \"red\", \"blue\"], [\"nature\", \"building\"], \"thumbnail\", \"landscape\"],\n",
    "    [[\"blue\"], [\"architecture\"], \"medium\", \"portrait\"],\n",
    "    [[\"blue\"], [\"people\"], \"medium\", \"landscape\"],\n",
    "    [[\"yellow\"], [\"nature\"], \"medium\", \"portrait\"],\n",
    "    [[\"green\", \"red\", \"blue\"], [\"nature\"], \"thumbnail\", \"landscape\"],\n",
    "    [[\"blue\"], [\"people\"], \"medium\", \"landscape\"],\n",
    "    [[\"blue\"], [\"nature\"], \"thumbnail\", \"portrait\"],\n",
    "    [[\"yellow\"], [\"architecture\"], \"thumbnail\", \"landscape\"],\n",
    "    [[\"blue\"], [\"people\"], \"medium\", \"portrait\"],\n",
    "    [[\"yellow\"], [\"nature\"], \"medium\", \"landscape\"],\n",
    "    [[\"yellow\"], [\"people\"], \"thumbnail\", \"portrait\"],\n",
    "    [[\"blue\"], [\"people\"], \"medium\", \"landscape\"],\n",
    "    [[\"red\"], [\"architecture\"], \"thumbnail\", \"landscape\"],\n",
    "]\n",
    "\n",
    "result = [\n",
    "    \"Favorite\",\n",
    "    \"NotFavorite\",\n",
    "    \"Favorite\",\n",
    "    \"Favorite\",\n",
    "    \"Favorite\",\n",
    "    \"Favorite\",\n",
    "    \"Favorite\",\n",
    "    \"NotFavorite\",\n",
    "    \"NotFavorite\",\n",
    "    \"Favorite\",\n",
    "    \"Favorite\",\n",
    "    \"NotFavorite\",\n",
    "    \"NotFavorite\",\n",
    "]\n",
    "\n",
    "i = 0\n",
    "for properties in data:\n",
    "    # Encode color and tags subarrays using OneHotEncoder\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "    color_data = onehot_encoder.fit_transform(properties[0])\n",
    "    category_data = onehot_encoder.fit_transform(properties[1])\n",
    "\n",
    "    # Encode size and orientation feature using LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    size_data = label_encoder.fit_transform(properties[2]).reshape(-1, 1)\n",
    "    orientation_data = label_encoder.fit_transform(properties[3]).reshape(-1, 1)\n",
    "    \n",
    "    data[i] = [color_data, category_data, size_data, orientation_data]\n",
    "    print(data[i])\n",
    "    \n",
    "    i+=1\n",
    "\n",
    "# X = list(zip(*encoded_data))  # Features\n",
    "# y = result  # Labels\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Train the logistic regression classifier\n",
    "# classifier = svm.SVC()\n",
    "# classifier.fit(X_train, y_train)\n",
    "\n",
    "# # Predictions\n",
    "# y_pred = classifier.predict(X_test)\n",
    "\n",
    "# # Evaluate the classifier\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# # Sample test data\n",
    "# test_data = [\n",
    "#     [[\"green\", \"blue\"], [\"nature\"], \"thumbnail\", \"landscape\"],\n",
    "#     [[\"red\"], [\"architecture\"], \"medium\", \"portrait\"],\n",
    "#     [[\"blue\", \"yellow\"], [\"people\"], \"medium\", \"landscape\"],\n",
    "# ]\n",
    "\n",
    "# # Encode test data using the same encoding schemes as the training data\n",
    "# test_color_data = onehot_encoder.transform([sublist[0] for sublist in test_data])\n",
    "# test_category_data = onehot_encoder.transform([sublist[1] for sublist in test_data])\n",
    "# test_size_data = label_encoder.transform([sublist[2] for sublist in test_data]).reshape(-1, 1)\n",
    "# test_orientation_data = label_encoder.transform([sublist[3] for sublist in test_data]).reshape(-1, 1)\n",
    "\n",
    "# # Concatenate encoded test data\n",
    "# X_test = np.concatenate((test_color_data, test_category_data, test_size_data, test_orientation_data), axis=1)\n",
    "\n",
    "# # Make predictions on test data\n",
    "# y_pred = classifier.predict(X_test)\n",
    "\n",
    "# # Print predictions\n",
    "# for i, prediction in enumerate(y_pred):\n",
    "#     print(f\"Prediction for test data {i+1}: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaad7db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6666666666666666\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: 'blue'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_encode.py:225\u001b[0m, in \u001b[0;36m_encode\u001b[0;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_map_to_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniques\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_encode.py:165\u001b[0m, in \u001b[0;36m_map_to_integer\u001b[0;34m(values, uniques)\u001b[0m\n\u001b[1;32m    164\u001b[0m table \u001b[38;5;241m=\u001b[39m _nandict({val: i \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(uniques)})\n\u001b[0;32m--> 165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([table[v] \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_encode.py:165\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    164\u001b[0m table \u001b[38;5;241m=\u001b[39m _nandict({val: i \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(uniques)})\n\u001b[0;32m--> 165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mtable\u001b[49m\u001b[43m[\u001b[49m\u001b[43mv\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_encode.py:159\u001b[0m, in \u001b[0;36m_nandict.__missing__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnan_value\n\u001b[0;32m--> 159\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'blue'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 81\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Sample prediction\u001b[39;00m\n\u001b[1;32m     80\u001b[0m sample_item \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnature\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedium\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlandscape\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# Sample item attributes\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m encoded_item \u001b[38;5;241m=\u001b[39m [label_encoders[i]\u001b[38;5;241m.\u001b[39mtransform([val])[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sample_item)]\n\u001b[1;32m     82\u001b[0m prediction \u001b[38;5;241m=\u001b[39m classifier\u001b[38;5;241m.\u001b[39mpredict([encoded_item])[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction for the sample item: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprediction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 81\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Sample prediction\u001b[39;00m\n\u001b[1;32m     80\u001b[0m sample_item \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnature\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedium\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlandscape\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# Sample item attributes\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m encoded_item \u001b[38;5;241m=\u001b[39m [\u001b[43mlabel_encoders\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mval\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sample_item)]\n\u001b[1;32m     82\u001b[0m prediction \u001b[38;5;241m=\u001b[39m classifier\u001b[38;5;241m.\u001b[39mpredict([encoded_item])[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction for the sample item: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprediction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:137\u001b[0m, in \u001b[0;36mLabelEncoder.transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([])\n\u001b[0;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniques\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_encode.py:227\u001b[0m, in \u001b[0;36m_encode\u001b[0;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _map_to_integer(values, uniques)\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 227\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my contains previously unseen labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check_unknown:\n",
      "\u001b[0;31mValueError\u001b[0m: y contains previously unseen labels: 'blue'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Sample data\n",
    "data = [\n",
    "    [[\"green\", \"red\", \"blue\", \"None\"], [\"nature\", \"building\", \"None\"], \"thumbnail\", \"landscape\"],\n",
    "    [[\"blue\", \"None\", \"None\", \"None\"], [\"architecture\", \"None\", \"None\"], \"medium\", \"portrait\"],\n",
    "    [[\"blue\", \"None\", \"None\", \"None\"], [\"people\", \"None\", \"None\"], \"medium\", \"landscape\"],\n",
    "    [[\"yellow\", \"None\", \"None\", \"None\"], [\"nature\", \"None\", \"None\"], \"medium\", \"portrait\"],\n",
    "    [[\"green\", \"red\", \"blue\", \"None\"], [\"nature\", \"None\", \"None\"], \"thumbnail\", \"landscape\"],\n",
    "    [[\"blue\", \"None\", \"None\", \"None\"], [\"people\", \"None\", \"None\"], \"medium\", \"landscape\"],\n",
    "    [[\"blue\", \"None\", \"None\", \"None\"], [\"nature\", \"None\", \"None\"], \"thumbnail\", \"portrait\"],\n",
    "    [[\"yellow\", \"None\", \"None\", \"None\"], [\"architecture\", \"None\", \"None\"], \"thumbnail\", \"landscape\"],\n",
    "    [[\"blue\", \"None\", \"None\", \"None\"], [\"people\", \"None\", \"None\"], \"medium\", \"portrait\"],\n",
    "    [[\"yellow\", \"None\", \"None\", \"None\"], [\"nature\", \"None\", \"None\"], \"medium\", \"landscape\"],\n",
    "    [[\"yellow\", \"None\", \"None\", \"None\"], [\"people\", \"None\", \"None\"], \"thumbnail\", \"portrait\"],\n",
    "    [[\"blue\", \"None\", \"None\", \"None\"], [\"people\", \"None\", \"None\"], \"medium\", \"landscape\"],\n",
    "    [[\"red\", \"None\", \"None\", \"None\"], [\"architecture\", \"None\", \"None\"], \"thumbnail\", \"landscape\"],\n",
    "]\n",
    "\n",
    "result = [\n",
    "    \"Favorite\",\n",
    "    \"NotFavorite\",\n",
    "    \"Favorite\",\n",
    "    \"Favorite\",\n",
    "    \"Favorite\",\n",
    "    \"Favorite\",\n",
    "    \"Favorite\",\n",
    "    \"NotFavorite\",\n",
    "    \"NotFavorite\",\n",
    "    \"Favorite\",\n",
    "    \"Favorite\",\n",
    "    \"NotFavorite\",\n",
    "    \"NotFavorite\",\n",
    "]\n",
    "\n",
    "# Flatten the data subarrays\n",
    "flat_data = []\n",
    "for sublist in data:\n",
    "    flat_array = []\n",
    "    for item in sublist:\n",
    "        if isinstance(item, list):\n",
    "            # If item is a list, flatten it and append its elements to flat_data\n",
    "            flat_array.extend(item)\n",
    "        else:\n",
    "            # If item is not a list, append it as is to flat_data\n",
    "            flat_array.append(item)\n",
    "            \n",
    "    flat_data.append(flat_array)\n",
    "    \n",
    "# Encode categorical features and labels\n",
    "label_encoders = [LabelEncoder() for _ in range(len(flat_data[0]))]\n",
    "encoded_data = []\n",
    "for i, column in enumerate(zip(*flat_data)):\n",
    "    encoded_data.append(label_encoders[i].fit_transform(column))\n",
    "\n",
    "X = list(zip(*encoded_data))  # Features\n",
    "y = result  # Labels\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the logistic regression classifier\n",
    "classifier = svm.SVC()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Sample prediction\n",
    "    \n",
    "sample_item = [\"green\", \"blue\", \"None\", \"None\", \"nature\", \"None\", \"None\", \"medium\", \"landscape\"]  # Sample item attributes\n",
    "encoded_item = [label_encoders[i].transform([val])[0] for i, val in enumerate(sample_item)]\n",
    "prediction = classifier.predict([encoded_item])[0]\n",
    "print(f\"Prediction for the sample item: {prediction}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
